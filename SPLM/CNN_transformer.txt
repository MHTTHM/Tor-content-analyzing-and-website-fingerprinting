MixedModel(
  (block1): Sequential(
    (0): Conv1d(1, 32, kernel_size=(8,), stride=(1,), padding=same)
    (1): ELU(alpha=1.0)
    (2): Conv1d(32, 32, kernel_size=(8,), stride=(1,), padding=same)
    (3): ELU(alpha=1.0)
    (4): MaxPool1d(kernel_size=4, stride=4, padding=1, dilation=1, ceil_mode=False)
    (5): Dropout(p=0.3, inplace=False)
  )
  (block2): Sequential(
    (0): Conv1d(32, 64, kernel_size=(8,), stride=(1,), padding=same)
    (1): ReLU()
    (2): Conv1d(64, 64, kernel_size=(8,), stride=(1,), padding=same)
    (3): ReLU()
    (4): MaxPool1d(kernel_size=4, stride=4, padding=1, dilation=1, ceil_mode=False)
    (5): Dropout(p=0.3, inplace=False)
  )
  (block3): Sequential(
    (0): Conv1d(64, 128, kernel_size=(8,), stride=(1,), padding=same)
    (1): ReLU()
    (2): Conv1d(128, 128, kernel_size=(8,), stride=(1,), padding=same)
    (3): ReLU()
    (4): MaxPool1d(kernel_size=4, stride=4, padding=1, dilation=1, ceil_mode=False)
    (5): Dropout(p=0.3, inplace=False)
  )
  (block4): Sequential(
    (0): Conv1d(128, 256, kernel_size=(8,), stride=(1,), padding=same)
    (1): ReLU()
    (2): Conv1d(256, 256, kernel_size=(8,), stride=(1,), padding=same)
    (3): ReLU()
    (4): AdaptiveAvgPool1d(output_size=8)
  )
  (transformer_blocks): ModuleList(
    (0): TransformerEncoderBlock(
      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
      )
      (dropout1): Dropout(p=0.1, inplace=False)
      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
      (dropout2): Dropout(p=0.1, inplace=False)
    )
    (1): TransformerEncoderBlock(
      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
      )
      (dropout1): Dropout(p=0.1, inplace=False)
      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
      (dropout2): Dropout(p=0.1, inplace=False)
    )
  )
  (pools): ModuleList(
    (0): AdaptiveAvgPool1d(output_size=4)
    (1): AdaptiveAvgPool1d(output_size=4)
  )
  (mlp): Sequential(
    (0): Linear(in_features=1024, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=128, out_features=64, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.1, inplace=False)
    (6): Linear(in_features=64, out_features=64, bias=True)
  )
)